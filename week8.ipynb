{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8: Text Mining\n",
    "\n",
    "### What's on this week\n",
    "1. [Loading text data](#load)\n",
    "2. [Data preprocessing and visualisation of text data](#prep)\n",
    "3. [Transformation on text data](#transform)\n",
    "4. [Document analysis](#analyse)\n",
    "\n",
    "---\n",
    "\n",
    "### Important Changelog:\n",
    "\n",
    "The practical note for this week introduces you to text document analysis and mining using Python. Python is the forefront text mining tool, with widely used text libraries like NLTK and gensim. You will learn how to preprocess text data, perform dimensionality transformation and cluster text documents based on their content. As the previous topic, the text analysis problem covered in this tutorial is **unlabelled**, but supervised/predictive text mining problems are just as common.\n",
    "\n",
    "**This tutorial notes is in experimental version. Please give us feedbacks and suggestions on how to make it better. Ask your tutor for any question and clarification.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Text Data\n",
    "\n",
    "We will be using Federalist Papers dataset in this tutorial. This dataset contains 85 news articles selected from many newspapers. Load the dataset using `.load_json` function from pandas. It is a little bit different from the usual `csv` files we have been using so far, but rest assured there is not much difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 85 entries, 0 to 9\n",
      "Data columns (total 11 columns):\n",
      "Attribution    85 non-null object\n",
      "Author         85 non-null object\n",
      "Filtered       85 non-null object\n",
      "ID             85 non-null float64\n",
      "Name           85 non-null object\n",
      "Size           85 non-null int64\n",
      "Target         73 non-null float64\n",
      "Text           85 non-null object\n",
      "Title          85 non-null object\n",
      "Truncated      85 non-null float64\n",
      "Unfiltered     85 non-null object\n",
      "dtypes: float64(3), int64(1), object(7)\n",
      "memory usage: 8.0+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('Federalistpapers.json')\n",
    "\n",
    "# as usual, explore the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, there are a number of columns in the dataset, covering information from ID, author, name, etc. There is one column that we are really interested in, which is the `text` column. This column contains the full text of each news article. Take a peek using `.get_value()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To the People of the State of New York: AFTER an unequivocal experience of the inefficiency of the subsisting federal government, you are called upon to deliberate on a new Constitution for the United\n"
     ]
    }
   ],
   "source": [
    "# print out the first 200 characters of the first row of text column\n",
    "print(df.get_value(index=0, col='Text')[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, the text column contains more than 13,000 characters. In this practical, we are only dealing with 85 documents, however, in many real world text mining problems you will be dealing with a lot more documents. This itself is a challenge for text data mining, particularly in this social media era."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13279.30588235294\n"
     ]
    }
   ],
   "source": [
    "# average length of text column\n",
    "print(df['Text'].apply(lambda x: len(x)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Prepocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different from tables and numbers that we have been working with so far in the semester, text data is considered as unstructured data and require preprocessing and transformation before it can be used as training data for machine learning algorithms. There are a number of different methods to represent text data depending on the need and objective of the data mining process, including bag of words, word2vec and sequential labels. In this tutorial, we will be using bag of words representation.\n",
    "\n",
    "In bag of words method, each individual document is split into tokens (a process called tokenisation). A token can be a single word, lemmatised word, or multiple consecutive words (also called as N-gram). There are many preprocessing methods typically used in tokenisation, and we will be using the following techniques:\n",
    "1. **Lowercase**: cast each word into its lowercased version. Ensure different capitalisations are treated as the same word.\n",
    "2. **Punctuation** removal: remove all punctuation marks.\n",
    "3. **Part of speech** filtering: keep tokens with certain part-of-speech only. In particular, here we are interested in adjective, adverb, noun and verbs.\n",
    "4. **Lemmatisation**: shaving tokens into their base form. Lemmatisation is slightly different from stemming that is discussed in the lecture. Stemming usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes. Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma. On the word \"ponies\" for example, stemming will return \"poni\", while lemmatisation will return \"pony\". [Source](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)\n",
    "\n",
    "These tokens are then transformed into matrices, with documents as rows and tokens as columns. Each cell is a statistical value of a token in the corresponding document. This statistical value can range from simply whether the token is present in the document (0/1, binary), the frequency of appearances, document frequency, or other more complex calculations (TF-IDF, BM25, etc).\n",
    "\n",
    "To perform the operations that we want, we need the `nltk` library, which should come by default in anaconda. If this is your first time doing this tutorial, you also need to download certain packages in nltk. Follow these steps:\n",
    "1. Open your anaconda prompt, type and run `ipython`.\n",
    "2. Import nltk by typing `import nltk`.\n",
    "3. A graphical window interface will open. Go to `All Packages` tab and download `WordNet` and `stopwords` package.\n",
    "\n",
    "Once you done this, import the following modules from nltk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk import sent_tokenize\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we implement our preprocessing steps, we need to load a number of different resources.\n",
    "1. Lemmatizer: We will use WordNet lemmatizer here. WordNet is a dictionary that maps english words into its lemma/base form using the part of speech tag. We will also implement the `lemmatize` function to help our lemmatisation process.\n",
    "2. Stopwords: List of words that we want to filter out. Both `nltk` and `sklearn` provide stopwords for English, but we have our own stopwords here.\n",
    "3. Punctuation: List of string punctuations (\",\", \".\", etc). Unnecessary for text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "punct = set(string.punctuation)\n",
    "\n",
    "df_stop = pd.read_json('Federaliststop.json')\n",
    "stopwords = set(df_stop['Term']).union(set(sw.words('english')))\n",
    "\n",
    "def lemmatize(token, tag):\n",
    "    tag = {\n",
    "        'N': wn.NOUN,\n",
    "        'V': wn.VERB,\n",
    "        'R': wn.ADV,\n",
    "        'J': wn.ADJ\n",
    "    }.get(tag[0], wn.NOUN)\n",
    "\n",
    "    return lemmatizer.lemmatize(token, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement our preprocessing method in the `cab_tokenizer` method. The purpose of this method is to take a document string, split it into tokens and preprocess them. The method will be quite long, but I have included many comments to help you understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cab_tokenizer(document):\n",
    "    # initialize token list\n",
    "    tokens = []\n",
    "    \n",
    "    # split the document into sentences\n",
    "    for sent in sent_tokenize(document):\n",
    "        # split the document into tokens and then create part of speech tag for each token\n",
    "        for token, tag in pos_tag(wordpunct_tokenize(sent)):\n",
    "            # preprocess and remove unnecessary characters\n",
    "            token = token.lower()\n",
    "            token = token.strip()\n",
    "            token = token.strip('_')\n",
    "            token = token.strip('*')\n",
    "\n",
    "            # If stopword, ignore token and continue\n",
    "            if token in stopwords:\n",
    "                continue\n",
    "\n",
    "            # If punctuation, ignore token and continue\n",
    "            if all(char in punct for char in token):\n",
    "                continue\n",
    "\n",
    "            # Lemmatize the token and add back to the token\n",
    "            lemma = lemmatize(token, tag)\n",
    "            tokens.append(lemma)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a tokenizer function, we need to *vectorise* or transform the tokens into matrices. `Sklearn` provides very convenient vectoriser classes to do this, count (which uses raw token count) and tfidf (which uses statistical function like tf-idf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# tf idf vectoriser\n",
    "tfidf_vec = TfidfVectorizer(tokenizer=cab_tokenizer, ngram_range=(1,2))\n",
    "X = tfidf_vec.fit_transform(df['Text'])\n",
    "\n",
    "# see the number of unique tokens produced by the vectorizer. Lots of them...\n",
    "print(len(tfidf_vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Document Analysis\n",
    "\n",
    "Using the vectorised term matrix, we now can perform text document clustering. Similar with previous week, we will use KMeans clustering procedure here. For demonstration purposes, we will set K=7 here, but you can find the \"optimal\" K using elbow method and silhouette score too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# K means clustering using the term vector\n",
    "kmeans = KMeans(n_clusters=7, random_state=42).fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the clustering is performed, the next important step is to know what kind of documents are in the clusters. We can do this by looking at the terms closest to the centroid of each clusters. This gives a pretty good sense of what is the main topic of each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms for cluster 0: providence, convention, congress, america, one, \n",
      "Top terms for cluster 1: state, government, power, would, may, \n",
      "Top terms for cluster 2: state, court, government, national, jurisdiction, \n",
      "Top terms for cluster 3: would, state, government, upon, nation, \n",
      "Top terms for cluster 4: department, government, legislative, may, power, \n",
      "Top terms for cluster 5: president, would, senate, power, state, \n",
      "Top terms for cluster 6: representative, state, government, election, may, \n"
     ]
    }
   ],
   "source": [
    "# function to visualise text cluster. Useful for the assignment too :)\n",
    "def visualise_text_cluster(n_clusters, cluster_centers, terms, num_word = 5):\n",
    "    # -- Params --\n",
    "    # cluster_centers: cluster centers of fitted/trained KMeans/other centroid-based clustering\n",
    "    # terms: terms used for clustering\n",
    "    # num_word: number of terms to show per cluster. Change as you please.\n",
    "    \n",
    "    # find features/terms closest to centroids\n",
    "    ordered_centroids = cluster_centers.argsort()[:, ::-1]\n",
    "    \n",
    "    for cluster in range(n_clusters):\n",
    "        print(\"Top terms for cluster {}:\".format(cluster), end=\" \")\n",
    "        for term_idx in ordered_centroids[cluster, :5]:\n",
    "            print(terms[term_idx], end=', ')\n",
    "        print()\n",
    "        \n",
    "# call it\n",
    "visualise_text_cluster(kmeans.n_clusters, kmeans.cluster_centers_, tfidf_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know the terms characterising each cluster. Unfortunately, we can see from this visualisation that the clustering solution does not really give good splits. This is caused by unimportant terms \"clouding\" the feature/term vector, resulting in reduced clustering performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Selection and Transformation\n",
    "\n",
    "### 3.1. Zipf's Law and Document Frequency Filtering\n",
    "\n",
    "Zipf's law is an empirical law based on distribution of phrases in many large collections of documents. It states that the frequency of a phrase will be inversely proportioned with its rank in the frequency table ([more info](https://en.wikipedia.org/wiki/Zipf%27s_law)). Zipf law can be observed when you plot document occurences vs term occurences from the vectorised terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFJCAYAAADaPycGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d99132b748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# visualisation of ZIPF law, a bit slow\n",
    "def visualise_zipf(document_col):\n",
    "    # Param - document_col: collection of raw document text that you want to analyse\n",
    "    \n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "    # use count vectorizer to find TF and DF of each term\n",
    "    count_vec = CountVectorizer(tokenizer=cab_tokenizer, ngram_range=(1,2))\n",
    "    X_count = count_vec.fit_transform(df['Text'])\n",
    "    \n",
    "    # create list of terms and their tf and df\n",
    "    terms = [{'term': t, 'idx': count_vec.vocabulary_[t],\n",
    "              'tf': X_count[:, count_vec.vocabulary_[t]].sum(),\n",
    "              'df': X_count[:, count_vec.vocabulary_[t]].count_nonzero()}\n",
    "             for t in count_vec.vocabulary_]\n",
    "    \n",
    "    # sort terms by its frequency\n",
    "    terms.sort(key=lambda x: (x['tf'], x['df']), reverse=True)\n",
    "    \n",
    "    # select a few of the terms for plotting purpose\n",
    "    sel_terms = [terms[i] for i in range(0, len(terms), 30)]\n",
    "    \n",
    "    # plot term frequency ranking vs log of its DF\n",
    "    plt.plot(range(len(sel_terms)), [x['df'] for x in sel_terms])\n",
    "    plt.show()\n",
    "    \n",
    "visualise_zipf(df['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The application of Zipf's law in text mining comes during feature selection process. Words that occured on the left side of the diagram above (high TF and high DF, too frequent) as well as the words on the right side of the diagram (low TF and low DF, too scarce) have no value to our clustering process. Filtering them and only keeping the middle ones will be beneficial, and we can do this through limiting the DF of terms that get through the vectoriser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8938\n"
     ]
    }
   ],
   "source": [
    "# another tf idf vectoriser\n",
    "# limit the terms produced to terms that occured at minimum 2 documents and maximum 80% of all documents\n",
    "filter_vec = TfidfVectorizer(tokenizer=cab_tokenizer, ngram_range=(1,2), min_df=2, max_df=0.8)\n",
    "X_filter = filter_vec.fit_transform(df['Text'])\n",
    "\n",
    "# see the number of unique tokens produced by the vectorizer. Reduced!\n",
    "print(len(filter_vec.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process greatly reduced the number of terms in our feature set. Let's try to cluster it again and see whether the clusters are more clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms for cluster 0: election, representative, knowledge, legislature, law, \n",
      "Top terms for cluster 1: convention, national, authority, form, republican, \n",
      "Top terms for cluster 2: upon, army, nation, national, militia, \n",
      "Top terms for cluster 3: representative, number, senate, interest, member, \n",
      "Top terms for cluster 4: president, senate, office, appointment, upon, \n",
      "Top terms for cluster 5: court, law, jurisdiction, authority, clause, \n",
      "Top terms for cluster 6: department, legislative, judiciary, legislative department, judiciary department, \n"
     ]
    }
   ],
   "source": [
    "# K means clustering using the new term vector\n",
    "kmeans_fil = KMeans(n_clusters=7, random_state=42).fit(X_filter)\n",
    "\n",
    "# visualisation\n",
    "visualise_text_cluster(kmeans_fil.n_clusters, kmeans_fil.cluster_centers_, filter_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With much less terms in the feature vector, the clustering process managed to result in much more meaningful solution. You can now see clear distinction between cluster topics, like taxation (#3), military (#1), parliament (#5), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Singular Value Decomposition\n",
    "\n",
    "Singular value decomposition is a dimensionality reduction method that works by factorizing a matrix. You have used SVD before with PCA, also a dimensionality reduction technique. In text mining, SVD is commonly used in technique called Latent Semantic Analysis, a method of analysing documents by finding the underlying meaning or concepts of words in these documents.\n",
    "\n",
    "[More info](https://en.wikipedia.org/wiki/Latent_semantic_analysis)\n",
    "\n",
    "LSA is typically used to help comparing and finding similar documents (like in document clustering and classification) and also finding synonymous/polysemous relationships between words. LSA can help in increasing speed (less features) and accuracy (comparison is now based on document concept similary instead of word similarity) of the model.\n",
    "\n",
    "In the following code, we will reduce the original `X` into only 100 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, random_state=42)\n",
    "X_trans = svd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the components produced by SVD contain weights associated with each word. The larger the weight is, the more connected the word is to the component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms in component #0 state, would, government, power, may, \n",
      "Top terms in component #1 senate, president, department, legislative, office, \n",
      "Top terms in component #2 court, law, power, judiciary, jurisdiction, \n",
      "Top terms in component #3 representative, state, election, government, year, \n",
      "Top terms in component #4 department, legislative, government, judiciary, legislative department, \n",
      "Top terms in component #5 court, jurisdiction, would, cause, state court, \n",
      "Top terms in component #6 would, legislative, representative, army, department, \n",
      "Top terms in component #7 taxation, tax, upon, revenue, merchant, \n",
      "Top terms in component #8 treaty, department, foreign, interest, trade, \n",
      "Top terms in component #9 government, state, would, national, department, \n"
     ]
    }
   ],
   "source": [
    "# sort the components by largest weighted word\n",
    "sorted_comp = svd.components_.argsort()[:, ::-1]\n",
    "terms = tfidf_vec.get_feature_names()\n",
    "\n",
    "# visualise word - concept/component relationships\n",
    "for comp_num in range(10):\n",
    "    print(\"Top terms in component #{}\".format(comp_num), end=\" \")\n",
    "    for i in sorted_comp[comp_num, :5]:\n",
    "        print(terms[i], end=\", \")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformed `X` can now be used for clustering. Let's see if it improve the quality of our clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms for cluster 0: providence, convention, congress, america, one, \n",
      "Top terms for cluster 1: state, government, power, would, may, \n",
      "Top terms for cluster 2: state, court, government, national, jurisdiction, \n",
      "Top terms for cluster 3: would, state, government, upon, nation, \n",
      "Top terms for cluster 4: department, government, legislative, may, power, \n",
      "Top terms for cluster 5: president, would, senate, power, state, \n",
      "Top terms for cluster 6: representative, state, government, election, may, \n"
     ]
    }
   ],
   "source": [
    "# K-means clustering using LSA-transformed X\n",
    "svd_kmeans = KMeans(n_clusters=7, random_state=42).fit(X_trans)\n",
    "\n",
    "# transform cluster centers back to original feature space for visualisation\n",
    "original_space_centroids = svd.inverse_transform(svd_kmeans.cluster_centers_)\n",
    "\n",
    "# visualisation\n",
    "visualise_text_cluster(svd_kmeans.n_clusters, original_space_centroids, tfidf_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hierarchical Clustering\n",
    "\n",
    "Do hierarchical clustering here.\n",
    "* Different with K-means, it is more similar with decision trees.\n",
    "* Fit with X from LSA\n",
    "* Plot the dendogram\n",
    "\n",
    "*Add more explanation here*\n",
    "*Need to plot the dendogram split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import Agglomerative a.k.a. hierarchical clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# fit it to X from LSA\n",
    "hier_clustering = AgglomerativeClustering(n_clusters=7).fit(X_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFDCAYAAAB7pARgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X1sW9d9//EPr/XQRBETC1Wb0pxDp3awGVoHlK6drLbb\nDvM0oBDgdVm9JAi6tXtIE6BT0/kBmSqxSJA0c9clM7ImW/8oYC9rKidTRuifrt5WxbagCWlSZE5X\nQUacH8gb1cqsgJLSSbTJ3x80KT5ckpdPl0/vF2BIOrz33O+9l+TxOeeec1zxeDwuAADgGKPeAQAA\n0G4ofAEAcBiFLwAADqPwBQDAYRS+AAA4rMOJgywuLqd+37z5Ri0tvZ/xulVaKduSJ3mSJ3mSJ3k2\nWp79/b05+SQ5XvPt6NhkK62UbcmTPMmTPMmTPBs1Tys0OwMA4DAKXwAAHEbhCwCAwyh8AQBwGIUv\nAAAOo/AFAMBhFL4AADiMwhcAAIdR+AIA4DAKXwAAHEbhCwCAwyh8AQBwmCOrGtVTINCtYHDjNA1D\nisV6MrapJI08yZM8K0sbGrqqQGAt5xhAK2v5mm8w2CHTdNU7DAAWTNOV8Z9joF20xbve44nr1VdX\nJSXWV1xcXM14vZI08iRP8iw/ze/PrVUD7aAtCl+gGujCqH6eyVYpv7+noeNstjyHhq7qmWdyDoMG\n0vLNzkC10IVRfR5PXB5PvN5htBSa8psDdwgoAV0Y5NnoedKU3xyo+QIA4DBqvgBQA4cPSy+84Hyf\nb7JrxOerT980/c32FC18o9Gojh07pnA4LMMw9Oijj6qjo0PHjh2Ty+XSjh07NDY2JsOgEg0ASePj\niYLQ6T7tjeM5/3xCsr+Zwre4ooXvj3/8Y129elXf//73de7cOT311FOKRqMaHh7Wnj17NDo6qjNn\nzujAgQNOxAsATSP9GQGpefuR7W5Lf7N9RQvfbdu26dq1a4rFYlpZWVFHR4def/117d69W5K0f/9+\nnTt3riqFby2GcqQPZahWnhKz8gAAyueKx+MF20TeeecdPfjgg3r//fe1tLSkZ599Vl/5yld09uxZ\nSdL09LRefPFFfetb38qbx9Wr19TRsaloMD6fFApJXm9pJ+G0ZIyXLtU7EjjJ50v85L7DjnZ8v7Tj\nOZeraM33e9/7nvbu3auvfe1reuedd/SFL3xB0Wg09frq6qrcbnfBPJaW3k/9nmiiWM54PZkWi/XI\n45FmZ1eLbltOWrXy9Pt7FIsp1dTSqHGSZ3XzTLZ6cN/J0962vYrFYhnNtI0YZzXz3GgtNBo6Tqfy\n7O/vzcknqWjh63a71dnZKUm6+eabdfXqVe3cuVMzMzPas2ePpqamdOeddxbLBm2m3C6EUrZ1Os9a\ndWFUO85y8uQJVcBZRR9R/qM/+iNduHBB9957r77whS/oq1/9qkZHR3XixAkdOnRI0WhUg4ODTsSK\nJtKKs0G16mxMzIgEOK/oJ66np0dPP/10TvqpU6dqEhBaRzmzQZWyLXnyhCrQrBicCwCAw2hrAgBI\n2nhWo9znB0qdXcsqvV2eP6DmCwCQVPmzGpU+F9FOzx+0x1kCAGzxeOK6dMlVl2cS2un5AwpfoAEU\nau6r9VCjajQVVprWLk2NQBLNzkADqOfQrHoPoWqnpkYgiXc80CDyNfc14/ClUtLaqakRSKLmCwCA\nw1qy5hsIdGtysnmnGaT/CwBaW0vWfIPBDoVCtcu/ln1k9H8BQOtr2W95r3djdaR09H8BAOqtZQtf\nALVz+LD0wgvV6WopdahTobShoasKBNbKOifASS3Z7AygtsbHVbWhUdXqxqHLBs2EdyqAsqSvWiXV\nv/tm69bWW+4RrYuaLwAADqPmi5RSpzjMl24YKns4llU6Q68AtBpqvkip5hSH9OMBQH58qyFDKVMc\n5ktnlRMAKIzCFwBQFZV2XVU67KyZhprR7AwAqIpKu64q6a5qti6q5okUANDw6tV11WxdVBS+AFBE\nsjlVsv/kvmlKkiujUCjW9NpMzaaoDM3OAFBEOc2pXq9KakJttmZTVIY7DQA2JGf0qtUT/szQ1V6o\n+QIA4DBqvjVS7qovlTxqT38RADQHar41Uu6qL+U+ak9/EQA0j6Lf1i+99JL+5V/+RZK0tramn/3s\nZ3r++ef1+OOPy+VyaceOHRobG5NhUI5nK3fVl1K2TaY122P2ANDOiha+n/vc5/S5z31OkvSNb3xD\nv//7v69nnnlGw8PD2rNnj0ZHR3XmzBkdOHCg5sGi+dR7xhuJhRkANB5XPB631cb5xhtv6K//+q91\n8uRJ7du3T1NTU3K5XPrRj36kc+fOaWxsLO++V69eU0fHpqLH8PkSPy9dshNR7fNpphiqcbxaxOzz\nSaFQYthFPSSPXc/3gh2N8J4tRSPGW8uYnDjfRrimlcZQz3NohOtXCtudhM8995weeughSVI8HpfL\nlaiR9PT0aHl5ueC+S0vvp35PNJNmbp9MS9ZYkk2rhbYtlBaL9cgwjJztKskzX1r+9F7FYrGMZuJK\n87R77crNc6PGmHvtKsnT45EuXapenqWk+f09isXsn1Mt71GhtFKvfb3i3FD++7tWccYSN7pqMVl9\nNvJ9vqpx7tnx1+N6FnofVrp/rd+fTtyjUvfv7+/NySfJVkdtJBLRW2+9pTvvvDOxU1r/7urqqtxu\nt51sAACAbNZ8Z2dnddddd6X+3rlzp2ZmZrRnzx5NTU2lCmUAG0rp7y6lb5s+bKD52ar5vvXWW/Km\nddodPXpUJ06c0KFDhxSNRjU4OFizAIFmVcqUhHaHmDGkDGgNtj7Ff/Inf5Lx97Zt23Tq1KmaBAS0\nkmqv8MKQMqA18F9oNI30lWWk2s0Y9tnPdjNTGICaYmYMNI1yVpYpdcawUEg06wKoOb5l0FTSZw2r\nxYxhn/hE7/WhSQBQO9R8AQBwGDVfAE2h2NCtZJdE+kNpDNNCo6LmC6ApFOvzL9a/zzAtNBLeiQCa\nRiVDtximhUZSt8I3fdhIsmkou9komc4i8QCAVlK3ZmerJiSrZiOaigAAraaupVpy2EihJqOtW+2P\n0QQAoBlQpQQANIRSFiPJTkvvtixnf8nZp+F52hkA0BDKmcUuqdTZ7LI53cVJzRcA0DBKeaK90hnt\n6vk0PDVfAAAcRs23jQUC3ZqczO0zyV4BiFmBAKC6qPm2sWCwQ6HQxt8M9QIAZ/Ct2ua8Xml2tnH6\nQQCgHTR94ZvddCpZT7Au0XwKAGgMTd/snN10KiWaT73ezDSaTwEAjaIlSqNiTacSzacAgMbR9DVf\nAACaTUvUfAGgUVmt4JbNMHKfVSk0HSIrvTU/ar4AUEN2p0y0Oz0iz6+0Bu4gANSYnRXc7E6HyEpv\nrYHCF4DlkD0pfzOpaUqSK+NBxkZbNQZoZDQ7A7AcsleI16uSV5ChuRTYYOuT8Nxzz+nf//3fFY1G\ndc8992j37t06duyYXC6XduzYobGxMRkG5TjQzOwM2SuU3mirxgCNrGiJOTMzo9dee03//M//rJMn\nT2phYUFPPPGEhoeH9fzzzysej+vMmTNOxAoAQEsoWvM9e/as7rjjDj300ENaWVnRkSNH9IMf/EC7\nd++WJO3fv1/nzp3TgQMHah6sXYWmnGTFHgBAvbni8XjBjpuRkRGZpqlnn31WoVBIX/7yl7W6uqqz\nZ89Kkqanp/Xiiy/qW9/6Vt48rl69po6OTRlpPl/i56VLhQMstp3V6z6fFAopZ4rJbMltisVQDrvn\nV8/j2dmn0vOo5nVw4po2ery1ugbNcG3ruX+99nUiv2rmXe/9K+H0sYvWfG+55Rbdfvvt6urq0u23\n367u7m4tLCykXl9dXZXb7S6Yx9LS+6nfE31Ay6na5+LiaiotW39/r2KxWGq79P2TYrEeGYaRk+b1\nGpqdtc4zua3f36NE9kbO8a1iKhRnbnoi9vQ+sErzLJRm93oWu3bZ2220EuRuZyfOQvuXeu7F3gvl\n5FnufbOTZzXPvZZ5JvMt9l4oNc9SYq90fztxlrq/1b75Pl/V/mwWSrPzOSg1z1a4R+VsW81zt0rr\n7+/NySepaJ+v3+/XK6+8ong8rl/84hf65S9/qbvuukszMzOSpKmpKe3atatYNmgTgUC3fL7Ef2z8\n/h6Zpkum6cpICwS66x0mANRV0ZrvZz7zGc3Ozuruu+9WPB7X6OiovF6vvv71r+vb3/62br/9dg0O\nDjoRK5pAYjYfyeNJ/L0xHCXR554cbsLUeADama2hRkeOHMlJO3XqVNWDQWsoNGSF4SYAwAxXyBII\njGhy8mXFYokaq2kmHqzz+fal0oaGDioQeKxuMQJAs2NmDGQIBicUSpvqyOPZK49nb+pv0wwrGJyo\nR2gA0DKo+SKH1+vV7OwbGWnJJ/j8/oE6RQUArYOaLwAADqPmi7YTWAgpGFmSMe9K9WMnmWsflyT5\n5zZq/unbDbk3K3BrkdlbAKAIar5oO8HIkszouuVr3pdek+f0TyxfM6PrCkaWahkagDZBzRdtydPZ\npUt33VXSjDXptWEAqASFb5NZWBhRJLLxtPH89SbRaDQxJGhubm8qTZLc7oO69VaGBQFAI6HwbTKR\nyISi0bA6O7dkpJ8+vTdn22g0rEhkgsIXABoMhW8T6uzcojvu+G9JhZtJ5+YYFgQAjYgHrgAAcBg1\nXwAtKbAQ0uT8extTpUYTw8h8068xdAx1R80XQEsKRpYUWttYPctz+icZw8gYOoZ6ouYLoGV5u7s1\nuz3z2QeGjqERUPgCQAMJBEYUDE7IMHJnYDMMl0zzFUmS3783lZa+HauONQeanQGggQSDEzLNcN7X\ns1caS8eqY82Dmi8ANBiPZ4suXbpU0gxsklh1rIlQ8wUAwGEUvigqEBiRz+eT3z8g0wzLNMPy+wfk\n9w/o8OHD9Q4PAJoOhS+KCgYnFAqFJCWawzyexNSWphnW+Ph4PUMDgKZEny9s8Xq9mp3NHJpB/xIA\nlIfCFw2pJzCi7vSnNg2XjOtDLPquD7GQ4VLf9SEWa0MHtcrwCgBNgmZnNKTu4ISMrOEWFz17ddFi\niIVhhjMLagBocNR80bBini268urG6k1XLIZYXFlcVh/N3wCaTFsVvnYmWpcSk60/0/9rdYkRAND6\n2qrwDUaWZEbX5enskqS0SdZdqW2Sk60/U4f4AADtwVbh+3u/93u66aabJCWeen3ggQd07NgxuVwu\n7dixQ2NjYzKM5ug+LjTRuiQmWwcA1FzRwndtbU3xeFwnT55MpT3wwAMaHh7Wnj17NDo6qjNnzujA\ngQM1DRQAgFZRtPD9n//5H/3yl7/UF7/4RV29elUPP/ywLly4oN27d0uS9u/fr3PnzlH4AgAaykIg\npEgwsWbzvMUqUelpUTPxDNC077Wc7az2dw9tVv8z5T8bVLTw/cAHPqAvfelL+oM/+ANdunRJf/qn\nf6p4PC6XK9FP2tPTo+Xl5YJ5bN58ozo6NqX+7u/vVbKVur+/N+NntmRzdvrr6b9n55MvTZKMeVfe\nYyXTktsU285OumEYOemV55l7DvnynLc43+LXLncfq7T82xaOye5931TCeSpr22LXs5x73N/fa/n+\nKfheMnLTih2nHnmm51vNPLPTisVe6f6lft6zX7dzbDvb5hzH5nt+41jlvT/T9y0nzsT+hberdP/i\n5176/oXynJ98T1FzXd3e7uv5u3K2S6a95H0tJy3ftmuhNa1Mvic9U1pM6YoWvtu2bdNtt90ml8ul\nbdu26ZZbbtGFCxdSr6+ursrtdhfMY2np/YygFheXFYv1SJIWF1ctV+pIbhuLxVLbpe+fFIv1yDCM\nommJ9LgMw1VwVZD0/9nYWVEkf3oi9mTc+bYrJc/E9YhnxFYoz2LbWl+73GuU77pZb2t97Uu979eu\nx37Fxnn2pW1r53qWeo/tXs/c4/RcT81/PQrF6VSeyXwL3bdy8iwl9kr3t9q32Oc9/X7aPXa+923h\n942993yl78/0fe2cU6HzdOoeVbp/sTxjsbg6PV3aPjtQ1vXIlz7nfyPn+8Bqu0KFcNGnpE6fPq1v\nfvObkqRf/OIXWllZ0Sc/+UnNzMxIkqamprRr165i2aCNBc6PyPeUT/6TAzJXwjJXwvKfHNDhH7Io\nA4D2VLTwvfvuu7W8vKx77rlHX/3qV/X444/rr/7qr3TixAkdOnRI0WhUg4ODTsSKJhW8OKFQ5PrC\nDCN75RnZK3MlrPE3WZQBQHsq2uzc1dWlv/mbv8lJP3XqVE0CQmvyur2avW9jGJf/JLNSAWhfzTE4\nFwCAFtJWM1wBpUqfktSMrkvamIjlUOTDOuL+UD3DA9CkqPkCBQQjSwqtrUmSPJ1dqalJzei6xi9f\nrmdoAJoYNV+gCKspSZmGFEAlKHwBAHVhZ6W5IfdmBW711i3GWqHZGQBQF+ndOlJipbmN1eY2Vplr\nRdR8AQB1U2iluVbu3qHmCwCAw6j5ouXl9islhgz5pqdbvl8JQGOi5ouWl9OvlDZkSGrtfiUAjYma\nL9pCu/YrAWhM1HzRlHoCI5LPpz7/gAwzLMMMq88/IB1mpSQAjY/CF02pOzghhRIrJcU8WxTzbJFh\nhqVxVkoC0Phodkbz8np1ZXajybjPP6BNdQwHAOyi8AUa2MLCiObnX049lR2NnpUkTU/vS6VJktt9\nUP39T9clRgClo/AFGlgkMqFoNKzOzi2SpNOn915/xZXaJhoNKxKZkEThCzQLCl+gwXV3e7V9e+YT\n2ckntSVpbm7AajcADYwHrgAAcBg1XwA1ETg/osm3NvqrzZVEf7XvqY3+6qGPHlTgNx+rW4xAvVDz\nBVATwYsTCkVCqb89I3vlGdmb+ttcCSt4caIeoQF1R80XQM143V7N3mfdX+0/SV812heFL1AlC4GQ\n5ic3FnCImomFwad9r2UOCxrarP5nfq0uMQJoDBS+QJVEgkuKmuvq9CQWbTjtSS4KnjYsyFxXJLgk\nPVOHAAE0DApfoIq6vd3aPmu9gIMkzflZxAEAD1wBAOC4hi18k6vWpK9Yw6o1AIBWYKvw/d///V99\n6lOf0sWLF/X222/rnnvu0b333quxsTHFYrGaBJZcteaiZ68uehLDE1i1BgDQCooWvtFoVKOjo/rA\nBz4gSXriiSc0PDys559/XvF4XGfOnKlddF6vrrz636l/Mc+W2h0LAACHFH3g6sknn9Qf/uEf6h/+\n4R8kSRcuXNDu3bslSfv379e5c+d04MCB2kYJAECd5A4jXJckTfumU2nuoc26NeC1nWfBwvell15S\nX1+f9u3blyp84/G4XK7E0Imenh4tLy8XPcjmzTeqo2NjpdX+/l4Zxsbv6T9TDFduukVadj750iTJ\nmLfIU5nbJrcptp2ddMMwctIrzzP3HPLlOW9xvsWvndU1tr5u1ttWlmfSpmLnafP9IRW/79mvZ8SZ\nZ1+r9PkC55RMS26Tb7ucPG28Z+eLvGeL7S/l/8xUlmeR617Cezk9RrtxVnLf8x3bzrY5x7Gxb+ax\nSv8Oyt63nDgT+xfertL9a3mPrNKzP5OlXo+k+cn3tBZaU7e3W5JSP6XENV8LrWll8r3U+P18MaUr\nWPi++OKLcrlcmp6e1s9+9jMdPXpUV65cSb2+uroqt9td9CBLS+9nnNTi4rJisR5J0uLiasZQjKS+\nWFybDFdGulVaLNYjwzCKpiXS4zKy9k+PKblNUqHtiqf3KhaLaXFxteB2peTZ39+bii/5WqE8i21r\nfe1yr1G+62a9bWV5JuO8dj32K3lit/v+KHQsq+uUe41KOffK3l9W51mLPK2PY/2ZKfX9WUrspbyX\nkzEm2Iuzkvue79j5vq8Kfw4L75t7rNK+g6z2tXNOhc7T6hpXun+t71G19s8XZ6FhhHP+NxSLxXOO\nU6gQLlj4/tM//VPq9/vvv1+BQEDHjx/XzMyM9uzZo6mpKd15552FsgAAAFlKnmTj6NGj+vrXv65v\nf/vbuv322zU4OFiLuBwTWAhpcn6jLd+MJtryfdMbbflD7s0K3Gq/LR8AgEJsF74nT55M/X7q1Kma\nBFMPwciSzOi6PJ2JKQGTP5PM6LqCkSUKXwBA1TC9pCRvd7dmt1u35fvnmA4QAFBdFL5Ak1lYGNH8\n/MYi9dFoWJI0Pe3bGPbgPqhbb2WReqBRNez0kgCsRSITWlvbWKS+s3OLOjs3JqCJRsOKRFikHmhk\n1HyBJtTd7dX27daL1M/NsUg90OgofAGgSQUCI5qc3OiCMM1EF4TfPyDDcCkWi2to6KACAbogGg3N\nzgDQpILBCYVCG10QHs8WedLmwDfNsIJBuiAaETVfAGhiXq9Xs7O5ozL6+3u1dettdYgIdlDzBQDA\nYdR8K5S92kXSmvlxSdKcf+N/pPPX+2Ck0lfAAAC0Dmq+FYoEl7QWWstJf8n7mk57fmK5T9RcVyS4\nVOvQAAANippvFRRa7cIqLb02DABoPxS+AICmthAIZbQmJrv4kovez/nfyOj2kxJdf8n1d+uBZmcA\nQFOLBJdSBW26Tk+XOj1dOemN0PVHzRcA0PQ6PV2649Vfl1S4209SQ3T9UfMFAMBh1HyBNpM9JaEk\nmeZZSS75/Z/M2PbQoc/ryJFRhyMEWh81X6DNZE9JKEkez155vXsz0kwzrPHxcSdDA9oGNV+gDVlN\nSZjdT+b3szoSUCsUvjVU6uPvzHoFAO2BZucaKuXx90Z49B0A4AxqvjVm9/H3Rnj0HQDgDGq+AAA4\njJovgDzDj8KSMh+8Gho6qEDgMcfjA1oNNV8AeYYfbZHXu/EAoGmGFQxOOB0a0JKo+QKQVHz4EUOP\ngOqh8AXQNgILIU3Ov6dYLC4zmhiJ4J97Q4ciH9YR94fqHB3aCc3OANpGMLKk0NqaJMnT2SVPZ5fM\n6LrGL1+uc2RoN0VrvteuXdPIyIjeeustuVwufeMb31B3d7eOHTsml8ulHTt2aGxsTIZBOQ6g8Xm7\nuzW7faMJ3T/HMD84r2jh+x//8R+SpO9///uamZnR3/7t3yoej2t4eFh79uzR6Oiozpw5owMHDtQ8\nWAAAWkHRwve3f/u39elPf1qSZJqm3G63zp8/r927d0uS9u/fr3PnzlH4AhYWAiHNT76XGsKTnPFs\n2jfNtKJAG7P1wFVHR4eOHj2qf/u3f9Pf/d3f6dy5c3K5XJKknp4eLS8vF9x/8+Yb1dGxKfV3f3+v\nkq3U/f29GT9TDFduukVadj750iTJmLfY3yItI86s17O3m7eKMxVH7mv5jmOVT8V5Wpxb8WtndY2t\nz9F628ryTNpU7Dxtvj+kyu5xvn2t0q3u4fzke1oLranb2y1JqZ9S4hqshda0Mvme+p/5NcvztLqH\nVmnp+xa/76Xdj2Ra9jaFtrWTZynv5UR+1sfJl2b3817s/ZF+bLvnnp5mZ9/MY7mK5pmKvcjnqNrX\nuNL9q/nZTN/O7vdnMm2+hGucvr3d4+e7dulsP+385JNP6i//8i/1+c9/XmvXH1iQpNXVVbnd7oL7\nLi29nxHo4uKyYrEeSdLi4qrltIt9sbg2Ga6MdKu0WKxHhmEUTUukx2Xk7J+blhln/Hqcy5ZxFto/\nfd/0PIsdp9C21czT+trZv0bW21aWZzLOa9djv5Indrvvj0LHsnOPSzt367Rub7e2z2YO00mfVjQW\nixe4R5W9Z6uVZ3KbfNfJ7nFKiTP3+D3XU3M/23Y/m+Wfe+Hvq8Kfw8L75h5rY6KTcq9xcttqXuNK\n9y/1+9PO92/57yX717iSOAsVwkWfkpqYmNBzzz0nSbrhhhvkcrk0MDCgmZkZSdLU1JR27dpVLBsA\nUOD8iHxP+eQ/OSBzJSxzJSz/yQH5Tw7o8A8P1zs8wDFFC9/f+Z3f0Ztvvqn77rtPX/rSl/TII49o\ndHRUJ06c0KFDhxSNRjU4OOhErACaXPDihEKRxExanpu2yHPTFkmSuRLW+Jvj9QwNcFTRZucbb7xR\nTz/9dE76qVOnahIQgNbmdXs1e1/m8B7/SWbPQnthhisAlrIXW0hfaMEwXIrF4iy0AJSJmTEAWMpe\nbMHj2SKPZ0vqbxZaAMpHzRdAXlaLLUiJpzi3br2tDhEBrYGaLwAADqPmi7bE6jYA6omaL9oSq9sA\nqCdqvmhbrG4DoF4ofC3QJAkAqCWanS3QJAkAqCVqvnnQJAkAqBVqvgAAOIyaL4CG1BMYkSZfVt/1\n6S0N82ziBd++VNra0EGtMr0lmhA1XwANqTs4IaVNb3nRs1cXPXtTfxtmOLEN0ISo+QJoXF6vrmRN\nb9nf36sri8vq87MSEpoXNV8AJQkERuTz+WSaYZlmWH7/gPz+AR0+fLjeoQFNg8IXQEmSqx2lr3Jk\nmmGNj4/XOTKgedDsDKBk2asd+WkCBkpCzRcAAIdR862jhUBI85OJaSyjZmIayzl/ojYROfRhuY8w\nlSUAtCJqvnUUCS5pLZSYxrLT06VOT5ckKWqu6/I4U1kCQKui5ltn3d5ubZ/N7C9L1n4BAK2Jwhdo\nAQsLI5qffznRhRENS5Lm5hL/qYtEPi+3e7Se4QHIQrMz0AIikQmtrSVmg+rs3KLOzsQQoGg0rMuX\nGQIENBpqvkCL6O72avv2zC6LZO0XQGOh8AWALOkjESQpan5cUuJ5jHnDpVgsLvfQZt0a8NYzTDQx\nmp0BIEv6SARJOu35iU57fpL6O2quKxJcqkdoaBEFa77RaFSPPPKIwuGw1tfX9eUvf1nbt2/XsWPH\n5HK5tGPHDo2NjckwKMMBtBarkQhSYmGHc1vP1yEitJKChe+//uu/6pZbbtHx48f13nvv6eDBg/rV\nX/1VDQ8Pa8+ePRodHdWZM2d04MABp+IFAKDpFayy/u7v/q7+4i/+QpIUj8e1adMmXbhwQbt375Yk\n7d+/X+fP8z9AVE9PYETy+WSYYRlmWH3+gcTScayYA6CFFKz59vT0SJJWVlb0la98RcPDw3ryySfl\ncrlSry8vLxc9yObNN6qjY1Pq7/7+XiVbqvv7ezN+phiu3HSLtOx88qVJkjFvsX8FaZI0bxVnKo7c\n19J/z7dvJXmmp81bxFz82lldY+t4rLetLE9NviyFQnJ5Ew+ybJISC6qPj6v/+PG0g9t7f0i1ue9W\n6Vb3rdCd+u9nAAALWUlEQVS97O/vtXw9Y3+r49hMy5du936Udt+rn2e++5lKy3q9mve90H3LF2++\nOIt+12Xtn8y7UJ6F4ig3zsT21sfJd/xS97dzj9K3zX693M9Rdtp8Cdc4fXu7x8937dIVfdr5nXfe\n0UMPPaR7771XQ0NDOp72Bbi6uiq32130IEtL72cEuri4rFgsUbAvLq6m0tL1xeLaZLgy0q3SYrEe\nGYZRNC2RHpeRs3/5aYXS+/t7U09KJl/LPs9a5JmeVvz4VteusnOvNM++WFybvF4tpq2Y0+cf0Ka0\n80htZ+P9UcrxKz93+/vbv0f1i7Peeea7n8lr1Hf92l1ZXLb8HNQizuTxS/scFv6uy94/mXd6/lbb\nVTvORH4911Nzvz8r3d/uPUrfNj3+Sr7rcuO0f40ribNQIVyw2fndd9/VF7/4RR0+fFh33323JGnn\nzp2amZmRJE1NTWnXrl2FsgCAqkl2S/T5BzK6JuiWQLMpWPg+++yzikQi+vu//3vdf//9uv/++zU8\nPKwTJ07o0KFDikajGhwcdCpWAG2uOziR6IaQFPNsUcyzRYYZlsaZxQvNpWCz88jIiEZGRnLST506\nVbOAAKAgr1dXLLolgGbCAF0AABzG9JIAUGWZq0ydlSTNze1lhSmkUPgCQJVFIhOKRsPq7Nyi06f3\nStpYYYrCFxKFLwDURPYqU6wwhXQUvgCAlpa7StW6JGnaN51Kc3qVKh64AgC0tOxVqjo9Xer0dKX+\nrscqVdR8AQAtz2qVquRsVHP+N/LsVTvUfAEAcBg1X8Bh6f1Pyb6n5P+8I4c+LPeRD9UzPAAOoOYL\nOCy9/ym97ylqruvy+OV6hgbAIdR8gTqw6n+qR78TgPqg8AWAOgoERjQ5+XJqyItphiVJPp8vlTY0\ndFCBwGN1ixHVR7MzANRRMDih0PWVmiTJ49kij2dL6m/TDCsYnKhHaKghar4AUGder1ezs5ndDslh\nMH4/M2O1IgpfALAp+aQ6T6mjUjQ7A4BNySfVeUodlaLmCwAlyH5SnafUUQ5qvgAAOIyab4vJXMQ7\nMWQhuZQZC3kDQGOg5ttiIpEJra0lhi10dm5RZ2diyEJyIW8AQP1R821B2Yt4SyzkDQCNhMIXAIAS\n5Vsgxe6wM5qdAQAokdUCKaUMO6PmCwBAGSoZdkbNFwAAh1H4AkCDCQRG5PP55PcPyDTDMs2w/P4B\nHT58uN6hoUpsFb4//elPdf/990uS3n77bd1zzz269957NTY2plgsVtMAAaDdpK90lFzlyDTDGh9n\nuGCrKFr4/uM//qNGRka0tpboWH7iiSc0PDys559/XvF4XGfOnKl5kADQbrxer1599b9T/9KXGUTz\nK1r4bt26VSdOnEj9feHCBe3evVuStH//fp0/f7520QEASpZstk5vsqbZurEUfdp5cHAwY6HneDwu\nl8slSerp6dHy8nLRg2zefKM6Ojal/u7v75VhbPye/jPFcOWmW6Rl55MvTZKMeYv9K0iTpHmrOFNx\n5L6W/nu+fSvKM1+cVudkee2strPO03rbyvK0e99tp6k2990q3eq+2U3Lu63VcWym5Uu3ez9Ku+/V\nz7Oe972ke1TBfZNqcz0nJ19WKBSS1+tNpYVCIY2Pj+v48ePKltzfMHLT8m1bzv527lH6ttmv59vO\n6h7YuZ/59i/7vhc4TraShxoZaVd3dXVVbre76D5LS++nfk8uEB2L9UiSFhdXU2np+mJxbTJcGelW\nabFYjwzDKJqWSI/LyNm//LRC6f39vYrF4tfPcTnj3BslT+trV9m5V5qn3ftuN62U41d+7uRZzTy5\n75Xl6fV6NTu7MfTF708MibH6XkmmJb+Xpdzvz+xtS93fat9C33WJcmLj+67Qscv9XrR7nHLvR6FC\nuOSnnXfu3KmZmRlJ0tTUlHbt2lVqFgAAtLWSC9+jR4/qxIkTOnTokKLRqAYHB2sRFwAANbMQCGna\nN605/xuKmuuKmuua87+hi4cvOnJ8W83OXq9XP/jBDyRJ27Zt06lTp2oaFAAAtRQJLilqrqemhpSU\nmh7SztzMlWJ6SQBAW6pkeshKUfgCABpGYCGkyfnEakFmNLFakH/uDR2KfFhH3LWvkTqF6SUBAA0j\nGFlS6PqkTp7OLnk6u2RG1zV+2d5qQc2Cmi8AoKF4u7s1u32jOdg/51xzsFMofGsguchy+gLLkmwv\nsgwAaG00O9dAcpFlq6foAACg5lsj9XyKDgDQ2Kj5AgDgMGq+TWJhYUTz8y8rGg1LkubmErXqSOTz\ncrtH6xkaAKBE1HybRCQyobW1kDo7t6izM7GuZzQa1uXLLK4NAM2Gmm8T6e72avv2jb7jZO0XANBc\nKHwBAGXpCYxIky+r7/qSfIZ5NvGCb18qbW3ooFYDj9UrxIZFszMAoCzdwQkpFEr9fdGzVxc9e1N/\nG2Y4sQ1yUPMFAJTP69WV2cyhlP39vbqyuKw+P11j+VDzBQDAYRS+AICq6QmMSD6f+vwDMsywDDOc\nqAEfPlzv0BoKhS8AoGrS+4Fjni2KebbIMMPSOMMi09HnCwCorqx+4D7/gDbVMZxGROELAGg6ydXj\nYrF4U64gR7MzAKDpJFePk9SUK8hR8wUANKXs1eOk5llBjpovAAAOo+YLAG0qcH5Ek2+9rNj1qSDN\nlcT0kL6n9qXShj56UIHfZHrIaqPmCwBtKnhxQqHIxvSQnpG98oxsTA9proQVvMj0kLVAzRcA2pjX\n7dXsfbnTQy4uLst/kukha8XRmm/g/Ih8T/nkPzkgcyUscyUs/8kBHf4hM58AANqHo4VvehNHsnnD\nXAlr/E1mPgEAtI+ymp1jsZgCgYB+/vOfq6urS4899phuu+02W/tmN3HQrAEAaDdlFb4/+tGPtL6+\nrhdeeEGvv/66vvnNb+o73/lOtWMDANSB7ymfYrG4zJWwpI1K0v97+O16htVSXPF4PF7qTk888YQ+\n9rGP6bOf/awkad++fXrllVeqHhwAAK2orD7flZUV3XTTTam/N23apKtXr1YtKAAAWllZhe9NN92k\n1dXV1N+xWEwdHYxaAgDAjrIK349//OOampqSJL3++uu64447qhoUAACtrKw+3+TTznNzc4rH43r8\n8cf10Y9+tBbxAQDQcsoqfAEAQPmY2xkAAIdR+AIA4DAKXwAAHOZo4Zs+PKkaaUnXrl0rO63S/Zs5\nT6vu/krS2jnPWCymWCxWtTTyrF+egBMcGZx7/PhxxeNxvfnmm9q5c6eOHDlSUZokPfroo3K5XLr7\n7rv1n//5n3rggQdsp1W6f7PnOT4+rs7OTv385z/XLbfcoj//8z+vKK3d8/zud7+rSCSieDyuvr4+\n/fEf/3FFaeRZvzy/853v6P/+7/+0vr6u3t5ePfjgg5Zpkmxv24h5Pv3007rtttv05ptv6oMf/KD+\n7M/+zHaaJP34xz/O+I7/1Kc+ZZlWyratmGchjtR8P/GJT+iuu+7SZz7zmVThWUmaJH3wgx/UyMiI\nfvjDH+rdd98tKa3S/Zs9T9M0FYlEdPToUXV3d1ec1u55dnV16eGHH9bXvvY1uVyuitPIs3553nzz\nzfqN3/gNHT16NDVxkFVaKds2Yp49PT1aWVnRI488oq6urpLSJOm//uu/tLy8rBtuuEE33HBD3rRS\ntm3FPAtxpOb76U9/Wj/96U915cqVqqRJ0kc+8hFdvnxZDz74oB599NGS0irdv9nz/JVf+RXNzc3p\nnXfeSX3pVJLW7nlu3bpVTz75pDo7O/Wxj32s4jTyrF+eN998s37rt35LFy9e1Ic+9KG8aaVs24h5\n7tixQ1NTUzp69GiqlmY3TZKGh4f17rvv6iMf+UjBtFK2bcU8C2GcLwAADuNpZwAAHEbhCwCAwyh8\nAQBwGIUvAAAO+//1jRR8TJzQjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d992763940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "# credit to Matthew Kalada\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Children of hierarchical clustering\n",
    "    children = model.children_\n",
    "\n",
    "    # Distances between each pair of children\n",
    "    # Since we don't have this information, we can use a uniform one for plotting\n",
    "    distance = np.arange(children.shape[0])\n",
    "\n",
    "    # The number of observations contained in each cluster level\n",
    "    no_of_observations = np.arange(2, children.shape[0]+2)\n",
    "\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "    linkage_matrix = np.column_stack([children, distance, no_of_observations]).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "\n",
    "# run the visualisation function\n",
    "plot_dendrogram(hier_clustering, labels=hier_clustering.labels_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
