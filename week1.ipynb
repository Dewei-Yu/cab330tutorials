{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Installing and Understanding Python's Data Mining Libraries\n",
    "\n",
    "### What's on this week\n",
    "1. [Why Python?](#whypython)\n",
    "2. [Installing Python and its data mining libraries](#install)\n",
    "3. [Process flow of predictive mining in Python](#processflow)\n",
    "4. [Interactive prototyping in ipython](#ipython)\n",
    "5. [Defining problem and purpose of data mining](#purpose)\n",
    "---\n",
    "\n",
    "The practical note for this week introduces you to Python and its common machine learning libraries. Python is a high-level, interpreted programming language. It is used for wide range of purposes, from web servers to scientific computing. Its syntax emphasizes on readibility, which allow anyone to learn and use it quickly.\n",
    "\n",
    "The practical sessions in this unit will be covering the usage of Python for data mining and machine learning purposes. We **WILL NOT ** cover the basics of Python. Fortunately, there is a lot of resources for learning Python from scratch, and you can reasonably learn the basics in a week.\n",
    "\n",
    "We will use Python 3 in this unit. All examples are written using Python 3.5.2, but any version of Python 3 above 3.4 should work just fine. \n",
    "\n",
    "## 1. Why Python? <a name=\"whypython\"></a>\n",
    "In the field of machine learning, Python is arguably the fastest growing and most widely used programming language alongside R. There are a number of reasons for this:\n",
    "\n",
    "### 1.1. Interpreted language.\n",
    "Python is designed as an interpreted language, which allow users to test and prototype models really quickly.\n",
    "\n",
    "### 1.2. Open-source\n",
    "Python is free and has no ties to any propertiary/corporate technologies, which makes Python the top choice for students, academics and startups.\n",
    "\n",
    "### 1.3. Fast and wide support for almost anything that you want to do\n",
    "\n",
    "Vast range of libraries for almost every data mining task.\n",
    "\n",
    "* **pandas** for data wrangling and preprocessing ([link](http://pandas.pydata.org/))\n",
    "* **scikit-learn** for supervised and unsupervised learning ([link](http://scikit-learn.org/stable/))\n",
    "* **numpy** for matrix manipulation ([link](http://www.numpy.org/))\n",
    "* **seaborn** and **matplotlib** for visualization ([link](https://seaborn.pydata.org/)) ([link2](https://matplotlib.org/))\n",
    "* **ipython** for interactive prototyping ([link](https://ipython.org/))\n",
    "\n",
    "\n",
    "### 1.4. Production ready\n",
    "Models and pipelines built with Python are very suitable to deployment in production systems.\n",
    "\n",
    "## 2. Installing Python and its data mining libraries <a name=\"install\"></a>\n",
    "\n",
    "### 2.1. For Windows Users\n",
    "\n",
    "((to do for windows users))\n",
    "\n",
    "Google \"Python 3\" and download it from the official website.\n",
    "\n",
    "### 2.2. For Linux Users\n",
    "\n",
    "Ubuntu/Linux Mint users are covered in this section. Typically, Python 3 comes pre-packaged with your distro installation. To check, write:\n",
    "\n",
    "``` bash\n",
    "whereis python3\n",
    "```\n",
    "\n",
    "Which should return the location of Python 3 binaries in your system\n",
    "``` bash\n",
    "python3: /usr/bin/python3 /usr/bin/python3.5m /usr/bin/python3.5 /usr/lib/python3 /usr/lib/python3.5 /etc/python3 /etc/python3.5 /usr/local/lib/python3.5 /usr/include/python3.5m /usr/share/python3 /usr/share/man/man1/python3.1.gz\n",
    "```\n",
    "\n",
    "If this is not the case with your system, please read section 2.2.1. Otherwise, you can skip to section 2.2.2.\n",
    "\n",
    "#### 2.2.1. Download and install Python\n",
    "Using your distro's package manager, download and install Python3. In Ubuntu/Linux Mint/Debian-based distros, type the following lines in your terminal\n",
    "\n",
    "```bash\n",
    "sudo apt-get update\n",
    "sudo apt-get upgrade\n",
    "sudo apt-get install python3\n",
    "```\n",
    "\n",
    "We also need to install additional libraries such as pip (Python's package manager).\n",
    "```bash\n",
    "sudo apt-get install python3-pip\n",
    "sudo apt-get install build-essential libssl-dev libffi-dev python-dev\n",
    "```\n",
    "\n",
    "#### 2.2.2. Setting up virtual environment\n",
    "Virtual environments enable you to have an isolated space for your Python projects, ensuring that each of your projects won't disrupt each other. This allows greater control over our Python projects and over how different versions of packages are handled. You can have as many virtual environments as you want.\n",
    "\n",
    "We need to first install the venv module. Let's do it by typing:\n",
    "```bash\n",
    "sudo apt-get install python3-venv\n",
    "```\n",
    "\n",
    "Once installed, we need to create environments. Choose which directory you would like to put the projects of this units in, or you could make a new one\n",
    "```bash\n",
    "mkdir /dir/to/your/project\n",
    "cd /dir/to/your/project\n",
    "```\n",
    "\n",
    "After you are in the directory, you can create an environment by running:\n",
    "```bash\n",
    "python3 -m venv my_env\n",
    "```\n",
    "\n",
    "This command creates a new directory that specifies the virtual environment. To activate it, type the following command:\n",
    "```bash\n",
    "source my_env/bin/activate\n",
    "```\n",
    "\n",
    "Your prompt will now be prefixed with the name of your environment, which in this case is called **my_env**. It should looks like this:\n",
    "```bash\n",
    "(my_env) hendi@hendi-HP-Pavilion-15-Notebook-PC ~/Documents/Tutoring/dataminingtutorials/week1 $\n",
    "```\n",
    "\n",
    "Within the virtual environment, you can use the command ```python``` instead of ```python3``` and pip instead of ```pip3```. If you use Python 3 outside of the environment, you would need to use ```python3``` and ```pip3``` commands as ```python``` and ```pip``` refers to the Python 2 packages.\n",
    "\n",
    "\n",
    "**NOTE:** You need to activate the virtual environment everytime you open a new terminal session to work on this directory. Otherwise, all libraries and setting you set up in the virtual environment would not be applied.\n",
    "\n",
    "#### 2.2.2. Install machine learning packages\n",
    "To install the libraries that we will use in this unit, we can use ```pip``` package manager by typing:\n",
    "```bash\n",
    "pip install ipython pandas sklearn matplotlib numpy seaborn nltk\n",
    "```\n",
    "\n",
    "## 3. Process flow for predictive mining using Python<a name=\"processflow\"></a>\n",
    "![Predictive mining process flow in Python](https://s3-ap-southeast-2.amazonaws.com/dataminingtuts/process_flow_python.png  \"Predictive mining process flow in Python\")\n",
    "\n",
    "The diagram above presents the steps we will take in this unit to perform predictive mining on the dataset. The first and most important step is to define problem and purpose of the data mining. You need to ask questions such as:\n",
    "\n",
    "* What kind of data do we have?\n",
    "* Why are we performing predictive mining on this data?\n",
    "* What information are we trying to predict?\n",
    "* How could the stakeholders (including yourself) use the insights we gained from the data mining?\n",
    "\n",
    "After we understand the problem and purpose of the data mining process, next step is to explore the data. In this step, we try to understand patterns and distributions in the data. We should also identifies problems in the dataset, such as noise and missing values, to be cleaned and processed out in the next step. Both steps will be performed mainly using ```pandas``` with some help from ```sklearn```'s preprocessing modules.\n",
    "\n",
    "Once the data is clean, it can be used to built predictive models. There are many algorithms available in ```sklearn```, each with its own characteristics. We will explore one algorithm at a time in the upcoming weeks.\n",
    "\n",
    "In all stages, we also need to visualize the patterns and trends found in the data. Visualization allows us to understand the data better. In this unit, all visualizations will be done using ```seaborn``` and ```matplotlib``` with data presented by ```pandas``` dataframes.\n",
    "\n",
    "\n",
    "## 4. Interactive prototyping with ipython<a name=\"ipython\"></a>\n",
    "\n",
    "```ipython``` is an interactive Python shell designed for fast prototyping. In data mining/machine learning, many engineers use ipython to quickly review the data and process they are working on. We can call ipython the same way as we call the python interpreter itself:\n",
    "\n",
    "```bash\n",
    "ipython\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Output\n",
    "Python 3.5.2 (default, Nov 17 2016, 17:05:23) \n",
    "Type 'copyright', 'credits' or 'license' for more information\n",
    "IPython 6.1.0 -- An enhanced Interactive Python. Type '?' for help.\n",
    "\n",
    "In [1]: \n",
    "```\n",
    "\n",
    "All examples in this unit are shown using ipython console.\n",
    "\n",
    "## 5. Defining problem and purpose of data mining process<a name=\"purpose\"></a>\n",
    "\n",
    "Let's start the data mining process by defining why we are performing data mining on this data. To do this, we need to take a look on the supplied **pva97nk** data.\n",
    "\n",
    "Start by importing the dataset into our ipython console. We will use pandas for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('pva97nk.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the dataset is imported, let's see what information it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9686 entries, 0 to 9685\n",
      "Data columns (total 28 columns):\n",
      "TargetB             9686 non-null int64\n",
      "ID                  9686 non-null int64\n",
      "TargetD             4843 non-null float64\n",
      "GiftCnt36           9686 non-null int64\n",
      "GiftCntAll          9686 non-null int64\n",
      "GiftCntCard36       9686 non-null int64\n",
      "GiftCntCardAll      9686 non-null int64\n",
      "GiftAvgLast         9686 non-null float64\n",
      "GiftAvg36           9686 non-null float64\n",
      "GiftAvgAll          9686 non-null float64\n",
      "GiftAvgCard36       7906 non-null float64\n",
      "GiftTimeLast        9686 non-null int64\n",
      "GiftTimeFirst       9686 non-null int64\n",
      "PromCnt12           9686 non-null int64\n",
      "PromCnt36           9686 non-null int64\n",
      "PromCntAll          9686 non-null int64\n",
      "PromCntCard12       9686 non-null int64\n",
      "PromCntCard36       9686 non-null int64\n",
      "PromCntCardAll      9686 non-null int64\n",
      "StatusCat96NK       9686 non-null object\n",
      "StatusCatStarAll    9686 non-null int64\n",
      "DemCluster          9686 non-null int64\n",
      "DemAge              7279 non-null float64\n",
      "DemGender           9686 non-null object\n",
      "DemHomeOwner        9686 non-null object\n",
      "DemMedHomeValue     9686 non-null int64\n",
      "DemPctVeterans      9686 non-null int64\n",
      "DemMedIncome        9686 non-null int64\n",
      "dtypes: float64(6), int64(19), object(3)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PVA97NK dataset is about a national veterans’ organization that seeks to better target its solicitations for donation. By only soliciting the most likely donors, less money will be spent on solicitation efforts and more money will be available for charitable concerns. Of particular interest is the class of individuals identified as lapsing donors. The organization seeks to classify its lapsing donors based on their responses to a greeting card mailing and calls it as the 97NK Campaign. With this classification, a decision can be made to either solicit or ignore a lapsing individual in next year campaign.\n",
    "\n",
    "The PVA97NK dataset contains 29 variables including identifiers, demographics of members, donation history of members, etc. In the upcoming weeks, we aim to predict TARGETB, a binary variable corresponding to whether or not someone responded to the greeting card mailing sent in June, 1997.\n",
    "\n",
    "## End notes and next week\n",
    "This week, we learned how to install Python and its libraries in a virtual enviroment. We also learned about the typical data mining process flow in Python and explored a bit of the dataset to understand why we are performing data mining on it.\n",
    "\n",
    "Next week, we will focus on exploring trends and performing data cleaning/preprocessing on the PVA97NK dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
